"""Summary formatting system for creating consistent digest output."""
import logging
from typing import List, Dict, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class SummaryFormatter:
    """Formats article summaries into consistent digest format."""
    
    def format_single_story(self, story: Dict, summary: Optional[str] = None, 
                           content_available: bool = True) -> str:
        """
        Format a single story with its summary.
        
        Args:
            story: Story dict with HN metadata and AI scoring
            summary: Generated summary text (optional)
            content_available: Whether article content was successfully scraped
        
        Returns:
            Formatted story text
        """
        title = story.get('title', 'Untitled')
        url = story.get('url', '')
        hn_score = story.get('score', 0)
        comments = story.get('descendants', 0)
        ai_score = story.get('ai_score', 0)
        matched_keywords = story.get('matched_keywords', [])
        
        # Header with title and scores
        header = f"**{title}**"
        if hn_score > 0:
            header += f" ({hn_score} points, {comments} comments)"
        
        # Add AI relevance info
        if ai_score > 0:
            keyword_text = ", ".join(matched_keywords[:3])  # Show first 3 keywords
            if len(matched_keywords) > 3:
                keyword_text += "..."
            header += f" [AI relevance: {ai_score}, keywords: {keyword_text}]"
        
        # Body with summary or fallback
        if summary and content_available:
            body = summary
        elif not content_available:
            body = "Article content could not be accessed. Please visit the original link for full details."
        else:
            body = "Summary not available. Please visit the original link for full details."
        
        # Footer with source link
        footer = f"Source: {url}" if url else "Source: HackerNews"
        
        return f"{header}\n\n{body}\n\n{footer}\n\n---\n"
    
    def format_digest(self, stories: List[Dict], summaries: Dict[str, str], 
                     generation_time: Optional[datetime] = None) -> str:
        """
        Format complete digest with all stories.
        
        Args:
            stories: List of story dicts
            summaries: Dict mapping story URLs to their summaries
            generation_time: When digest was generated
        
        Returns:
            Complete formatted digest text
        """
        if not stories:
            return "No AI-related stories found in today's HackerNews digest.\n"
        
        # Header
        gen_time = generation_time or datetime.now()
        digest_header = f"""HackerNews AI Digest - {gen_time.strftime('%B %d, %Y')}

Found {len(stories)} AI-related stories from HackerNews top stories.

"""
        
        # Format each story
        formatted_stories = []
        for i, story in enumerate(stories, 1):
            url = story.get('url', '')
            summary = summaries.get(url, None)
            content_available = url in summaries if summaries else False
            
            story_text = self.format_single_story(story, summary, content_available)
            formatted_stories.append(f"{i}. {story_text}")
        
        # Footer
        digest_footer = f"""
Generated by HN-Digest at {gen_time.strftime('%Y-%m-%d %H:%M:%S')}
Total stories processed: {len(stories)}
"""
        
        return digest_header + "\n".join(formatted_stories) + digest_footer
    
    def create_debug_summary(self, stories: List[Dict], scraping_stats: Dict) -> str:
        """Create a debug summary with scraping statistics."""
        total_stories = len(stories)
        successful_scrapes = scraping_stats.get('successful_scrapes', 0)
        failed_scrapes = scraping_stats.get('failed_scrapes', 0)
        summaries_generated = scraping_stats.get('summaries_generated', 0)
        
        debug_text = f"""
Debug Summary:
- Total AI stories found: {total_stories}
- Successful article scrapes: {successful_scrapes}
- Failed scrapes: {failed_scrapes}
- AI summaries generated: {summaries_generated}
- Success rate: {(successful_scrapes/total_stories*100) if total_stories > 0 else 0:.1f}%

Scraping failures by reason:
"""
        
        failure_reasons = scraping_stats.get('failure_reasons', {})
        for reason, count in failure_reasons.items():
            debug_text += f"- {reason}: {count}\n"
        
        return debug_text